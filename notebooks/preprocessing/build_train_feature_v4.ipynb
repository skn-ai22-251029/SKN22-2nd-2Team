{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Train Feature Table V4 (Strategic Features)\n",
    "\n",
    "이 노트북은 `kkbox_train_feature_v3.parquet`를 기반으로, 모델 보고서에서 제안된 **전략적 파생 변수(Strategic Derived Features)**를 추가하여 V4 데이터셋을 생성합니다.\n",
    "\n",
    "## 추가되는 피처 (New Features)\n",
    "1. **`active_decay_rate`**: 최근 활동 감소율 (w7 vs w30)\n",
    "2. **`listening_time_velocity`**: 청취 시간 가속도 (w7 - w14)\n",
    "3. **`discovery_index`**: 탐색 지수 (Unique 곡 비중)\n",
    "4. **`skip_passion_index`**: 스킵 열정도 (25% 미만 / 100% 청취)\n",
    "5. **`last_active_gap`**: 마지막 접속 경과일 (잠수 유저 포착) - *Raw Log 처리 필요*\n",
    "6. **`daily_listening_variance`**: 청취 루틴 안정성 -> 기존 `std_secs_w7` 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fe4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234699ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "if os.getcwd().endswith(\"preprocess\"):\n",
    "    os.chdir(\"../..\")\n",
    "    \n",
    "DATA_DIR = \"data/processed\"\n",
    "RAW_DATA_DIR = \"data/raw\"\n",
    "V3_PATH = os.path.join(DATA_DIR, \"kkbox_train_feature_v3.parquet\")\n",
    "USER_LOGS_PATH = os.path.join(RAW_DATA_DIR, \"user_logs_v2.csv\")\n",
    "OUTPUT_PATH = os.path.join(DATA_DIR, \"kkbox_train_feature_v4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6cff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading V3 Data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed\\\\kkbox_train_feature_v3.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading V3 Data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_v3 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV3_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mV3 Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_v3.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\WORK\\anaconda3\\envs\\project-2nd\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\WORK\\anaconda3\\envs\\project-2nd\\Lib\\site-packages\\pandas\\io\\parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\WORK\\anaconda3\\envs\\project-2nd\\Lib\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\WORK\\anaconda3\\envs\\project-2nd\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed\\\\kkbox_train_feature_v3.parquet'"
     ]
    }
   ],
   "source": [
    "print(\"Loading V3 Data...\")\n",
    "df_v3 = pd.read_parquet(V3_PATH)\n",
    "print(f\"V3 Shape: {df_v3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. V3 기반 파생 변수 생성 (Arithmetic Derived Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4 = df_v3.copy()\n",
    "\n",
    "# 1. Active Decay Rate (활동 감소율)\n",
    "# Logic: (w7 active days) / (w30 active days / 4). If w30 is 0, set to 0 (or 1? 0 means no activity).\n",
    "# epsilon to avoid division by zero\n",
    "epsilon = 1e-6\n",
    "df_v4['active_decay_rate'] = df_v4['num_days_active_w7'] / ((df_v4['num_days_active_w30'] / 4) + epsilon)\n",
    "\n",
    "# 2. Listening Time Velocity (청취 가속도)\n",
    "# Logic: w7 avg secs - w14 avg secs\n",
    "df_v4['listening_time_velocity'] = df_v4['avg_secs_per_day_w7'] - df_v4['avg_secs_per_day_w14']\n",
    "\n",
    "# 3. Discovery Index (탐색 지수)\n",
    "# Logic: num_unq_w7 / num_songs_w7\n",
    "df_v4['discovery_index'] = df_v4['num_unq_w7'] / (df_v4['num_songs_w7'] + epsilon)\n",
    "\n",
    "# 4. Skip Passion Index (스킵 열정도)\n",
    "# Logic: num_25_w7 / num_100_w7\n",
    "df_v4['skip_passion_index'] = df_v4['num_25_w7'] / (df_v4['num_100_w7'] + epsilon)\n",
    "\n",
    "# 5. Daily Listening Variance (Renaming existing feature for clarity)\n",
    "df_v4['daily_listening_variance'] = df_v4['std_secs_w7']\n",
    "\n",
    "# 6. Engagement Density (몰입 밀도)\n",
    "# Logic: total_secs_w7 / num_days_active_w7. Note: This assumes avg_secs_per_day_w7 is calculated this way.\n",
    "# Let's create it explicitly to be sure.\n",
    "df_v4['engagement_density'] = df_v4['total_secs_w7'] / (df_v4['num_days_active_w7'] + epsilon)\n",
    "\n",
    "print(\"Derived features created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Log 기반 피처 생성 (Last Active Gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Raw User Logs for Last Active Gap...\")\n",
    "# user_logs_v2.csv is large, read necessary columns only\n",
    "chunks = pd.read_csv(USER_LOGS_PATH, usecols=['msno', 'date'], chunksize=1000000)\n",
    "\n",
    "last_active_df = pd.DataFrame()\n",
    "\n",
    "# Find max date per user in chunks\n",
    "max_dates = []\n",
    "for chunk in chunks:\n",
    "    chunk_max = chunk.groupby('msno')['date'].max()\n",
    "    max_dates.append(chunk_max)\n",
    "\n",
    "# Combine and find global max per user\n",
    "all_max_dates = pd.concat(max_dates)\n",
    "final_last_active = all_max_dates.groupby(level=0).max().reset_index()\n",
    "final_last_active.rename(columns={'date': 'last_active_date'}, inplace=True)\n",
    "\n",
    "# Convert to datetime\n",
    "final_last_active['last_active_date'] = pd.to_datetime(final_last_active['last_active_date'], format='%Y%m%d')\n",
    "\n",
    "print(f\"Max Active Dates Calculated. Users: {len(final_last_active)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Study Cutoff Date\n",
    "# The training data (v3) is likely based on a specific month (e.g., March 2017).\n",
    "# Let's check the max date in the logs to be consistent, or assume the end of the logs is the cutoff.\n",
    "global_max_date = final_last_active['last_active_date'].max()\n",
    "print(f\"Global Max Date in Logs: {global_max_date}\")\n",
    "\n",
    "# Calculate Gap\n",
    "final_last_active['last_active_gap'] = (global_max_date - final_last_active['last_active_date']).dt.days\n",
    "\n",
    "print(final_last_active[['msno', 'last_active_gap']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with V4 DataFrame\n",
    "df_v4 = df_v4.merge(final_last_active[['msno', 'last_active_gap']], on='msno', how='left')\n",
    "\n",
    "# Fill NA for users with no logs (unlikely if they are in train set, but possible)\n",
    "# If no log, gap is large number?? or -1?\n",
    "# Assign a large number (e.g., 999) or the max gap found\n",
    "max_gap_found = df_v4['last_active_gap'].max()\n",
    "df_v4['last_active_gap'] = df_v4['last_active_gap'].fillna(max_gap_found + 1)\n",
    "\n",
    "print(\"Merged Last Active Gap.\")\n",
    "print(df_v4[['msno', 'last_active_gap']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 저장 (Save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving V4 to {OUTPUT_PATH}...\")\n",
    "df_v4.to_parquet(OUTPUT_PATH, index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Features\n",
    "print(\"New Feature Statistics:\")\n",
    "new_cols = ['active_decay_rate', 'listening_time_velocity', 'discovery_index', 'skip_passion_index', 'last_active_gap']\n",
    "print(df_v4[new_cols].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-2nd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
